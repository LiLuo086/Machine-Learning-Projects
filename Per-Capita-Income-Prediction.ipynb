{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"source":"<a href=\"https://www.kaggle.com/code/lxlz1986/per-capita-income-prediction?scriptVersionId=142997160\" target=\"_blank\"><img align=\"left\" alt=\"Kaggle\" title=\"Open in Kaggle\" src=\"https://kaggle.com/static/images/open-in-kaggle.svg\"></a>","metadata":{},"cell_type":"markdown"},{"cell_type":"markdown","source":"# Table of Contents\n 1. [Introduction](#Introduction) \n 2. [Get the Data and Explore the Dataset](#Get-the-Data-and-Explore-the-Dataset)\n 3. [Data visualization and Analysis](#Data-visualization-and-Analysis)\n 4. [Model trainning](#Model-trainning)\n 5. [Model Validation](#Model-Validation)\n 6. [Prediction Visulization](#Prediction-Visulization)\n","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2023-09-14T09:17:44.887203Z","iopub.execute_input":"2023-09-14T09:17:44.887678Z","iopub.status.idle":"2023-09-14T09:17:44.896148Z","shell.execute_reply.started":"2023-09-14T09:17:44.887641Z","shell.execute_reply":"2023-09-14T09:17:44.894705Z"}}},{"cell_type":"markdown","source":"*************************************************************************************************","metadata":{}},{"cell_type":"markdown","source":"## 1. Introduction\nIn this project, we will use a simple dataset to learn how to complete a machine learning project with the guide of machine learning pipeline. \nThe goal of the project is to use available features in a dataset to make predictions. Concretely, using the single feature *year* to perdict *per capita income* in the future.\n\nThe models we used here are two regression models: **Linear Regression** and **Polynomial Regression**, and both of them are the basic and important machine learning algorithms.  \n\n### About the Dataset\nThe pubic dataset [Canada_per_capita_income](https://www.kaggle.com/datasets/amalab182/canada-per-capita-income) provides the average income per capita over a specific period(from 1970 to 2016) in Canada and includes totally 47 rows and 2 columns: **year** and **income**. The information contained in this dataset can help people better understand the economic trends in Canada.\n\n\nAfter Exporing the dataset we will find that this dataset in practice could not prodive sufficient information to predict the income, since only the single feature **year** cannot determin the **income**, or income is not much relevant to the years number. However, it is still a good example to demonstrate the machine learning pipeline and how to train a Linear Regression model in Scikit-Learn at the beginning. ","metadata":{}},{"cell_type":"markdown","source":"*************************************************************************************************","metadata":{}},{"cell_type":"markdown","source":"## 2. Get the Data and Explore the Dataset","metadata":{}},{"cell_type":"code","source":"# import necessary python packages\n\nimport pandas as pd\nimport numpy as np\nimport pandas as pd\n\n\n# import matplotlib package\nimport matplotlib as mpl\nimport matplotlib.pyplot as plt\n\n# import relevant machine learninging packages from Scikit-Learn\nfrom sklearn.model_selection import train_test_split # dataset splitting\nfrom sklearn.linear_model import LinearRegression # Linear Regression model\nfrom sklearn.metrics import mean_squared_error # evaluation metric Mean Squared Error(MSE)\nfrom sklearn.preprocessing import PolynomialFeatures # feature extending in Polynomia Regression model\nfrom sklearn.model_selection import cross_val_score # cross-validation model","metadata":{"execution":{"iopub.status.busy":"2023-09-14T13:35:28.335423Z","iopub.execute_input":"2023-09-14T13:35:28.33598Z","iopub.status.idle":"2023-09-14T13:35:28.344862Z","shell.execute_reply.started":"2023-09-14T13:35:28.335936Z","shell.execute_reply":"2023-09-14T13:35:28.343584Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Import dataset into a DataFrame **capita_GDP**.","metadata":{}},{"cell_type":"code","source":"capita_GDP = pd.read_csv('/kaggle/input/canada-per-capita-income/Canada_per_capita_income.csv')","metadata":{"execution":{"iopub.status.busy":"2023-09-14T13:35:28.347643Z","iopub.execute_input":"2023-09-14T13:35:28.348549Z","iopub.status.idle":"2023-09-14T13:35:28.371427Z","shell.execute_reply.started":"2023-09-14T13:35:28.348502Z","shell.execute_reply":"2023-09-14T13:35:28.369671Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Explore dataset using `info()` function to get the general infomation about the datasest, such as the number of rows, columns and data type of each column.","metadata":{}},{"cell_type":"code","source":"capita_GDP.info()","metadata":{"execution":{"iopub.status.busy":"2023-09-14T13:35:28.374417Z","iopub.execute_input":"2023-09-14T13:35:28.376004Z","iopub.status.idle":"2023-09-14T13:35:28.393754Z","shell.execute_reply.started":"2023-09-14T13:35:28.375937Z","shell.execute_reply":"2023-09-14T13:35:28.392124Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Looking at the first 5 records in the dataset.","metadata":{}},{"cell_type":"code","source":"capita_GDP.head()","metadata":{"execution":{"iopub.status.busy":"2023-09-14T13:35:28.397135Z","iopub.execute_input":"2023-09-14T13:35:28.39793Z","iopub.status.idle":"2023-09-14T13:35:28.412578Z","shell.execute_reply.started":"2023-09-14T13:35:28.397878Z","shell.execute_reply":"2023-09-14T13:35:28.410992Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## 3. Data visualization and Analysis","metadata":{}},{"cell_type":"markdown","source":"Since there are only two columns in the dataset,in order to have a big picture of the dataset and relationship among data we can plot the dataset with the help of `matlibplot`. ","metadata":{}},{"cell_type":"code","source":"plt.figure(figsize=(10, 6)) # set figure size\nplt.plot(capita_GDP[\"year\"], capita_GDP[\"income\"], 'b.') # plot 'income' vs.'year'\nplt.title('Cancada per capita income over years') # add figure title\nplt.xlabel(\"Year\") # add x-axis label\nplt.ylabel(\"Per Capita Income\") # add y-axis label\nplt.axis([1970,2025,0,50000])# set axis range\nplt.grid(True)# show grid in the figure\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2023-09-14T13:35:28.41977Z","iopub.execute_input":"2023-09-14T13:35:28.420809Z","iopub.status.idle":"2023-09-14T13:35:28.806611Z","shell.execute_reply.started":"2023-09-14T13:35:28.420754Z","shell.execute_reply":"2023-09-14T13:35:28.804801Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"From the figure we find that the relationship between **income** and **year** is not ideal linear. In order to predict income for future, we can try both Linear Regression model and Polynommial Regression model.","metadata":{}},{"cell_type":"markdown","source":"## 4. Model trainning\n### 4.1 Choosing prediction target and features","metadata":{}},{"cell_type":"code","source":"# Chose column income as prediction target y\ny = capita_GDP[['income']]\n\n# Chose column year as Feature X\nX= capita_GDP[['year']]","metadata":{"execution":{"iopub.status.busy":"2023-09-14T13:35:28.809009Z","iopub.execute_input":"2023-09-14T13:35:28.810583Z","iopub.status.idle":"2023-09-14T13:35:28.821284Z","shell.execute_reply.started":"2023-09-14T13:35:28.810526Z","shell.execute_reply":"2023-09-14T13:35:28.81944Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### 4.2 Data splitting\nHier we need to splite the dataset into training dataset to train the model and test dataset to validate/evaluate the trained model. We will typically choose 20% of the data for validation and the rest for training purpose.","metadata":{}},{"cell_type":"code","source":"# Split the data randomly into training and testing sets\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)","metadata":{"execution":{"iopub.status.busy":"2023-09-14T13:35:28.823296Z","iopub.execute_input":"2023-09-14T13:35:28.823758Z","iopub.status.idle":"2023-09-14T13:35:28.842566Z","shell.execute_reply.started":"2023-09-14T13:35:28.823718Z","shell.execute_reply":"2023-09-14T13:35:28.837718Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### 4.3 Model training using Linear Regression and Polymonial Regression","metadata":{}},{"cell_type":"code","source":"# Perform Linear Regression\nlinear_reg_model = LinearRegression()\nlinear_reg_model.fit(X_train, y_train) # model training using training dataset\nlinear_reg_model.intercept_, linear_reg_model.coef_ # check the bais term and feature weight in the trained model","metadata":{"execution":{"iopub.status.busy":"2023-09-14T13:35:28.845247Z","iopub.execute_input":"2023-09-14T13:35:28.846703Z","iopub.status.idle":"2023-09-14T13:35:28.863423Z","shell.execute_reply.started":"2023-09-14T13:35:28.846642Z","shell.execute_reply":"2023-09-14T13:35:28.862056Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Before we train a Polynomia Regression model, we need to extend the features in the original dataset and then use the extended features to train a Linear Regression model. For fundamentals about Polynomial Regression in Scikit-Learn, please reference [Polynomial Regression in Scikit-Learn](https://www.kaggle.com/code/lxlz1986/polynomial-regression-in-scikit-learn).","metadata":{}},{"cell_type":"code","source":"# Extend features\npoly_features = PolynomialFeatures(degree = 2)\nX_poly_train = poly_features.fit_transform(X_train)\n\n# Use extended features to train linear regression model\npoly_reg_model = LinearRegression()\npoly_reg_model.fit(X_poly_train, y_train)\n","metadata":{"execution":{"iopub.status.busy":"2023-09-14T13:35:28.865022Z","iopub.execute_input":"2023-09-14T13:35:28.866463Z","iopub.status.idle":"2023-09-14T13:35:28.890497Z","shell.execute_reply.started":"2023-09-14T13:35:28.866405Z","shell.execute_reply":"2023-09-14T13:35:28.889182Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## 5. Model Validation\nHere we will use evaluate the model performance using metrics **Mean Squared Error(MSE)** and **Root Mean Squared Error(RMSE)**.","metadata":{}},{"cell_type":"code","source":"# Evaluate Linear Regression model\ny_linear_reg = linear_reg_model.predict(X_test)\nlinear_reg_mae = mean_squared_error(y_test,y_linear_reg)\nlinear_reg_rmae = np.sqrt(linear_reg_mae)\n\n# Evaluate Polynomial Regression model\nX_poly_test = poly_features.fit_transform(X_test)\ny_poly_reg = poly_reg_model.predict(X_poly_test)\npoly_reg_mae = mean_squared_error(y_test, y_poly_reg)\npoly_reg_rmae = np.sqrt(poly_reg_mae)\n\nprint(\"Evaluation of Linear Regression Model\")\nprint(\"Mean Squared Error(MSE):\", linear_reg_mae)\nprint(\"Root Mean Squared Error(RMSE):\", linear_reg_rmae)\n\nprint(\"\\nEvaluation of Polynommial Regression Model\")\nprint(\"Mean Squared Error(MSE):\", poly_reg_mae)\nprint(\"Root Mean Squared Error(RMSE):\", poly_reg_rmae)","metadata":{"execution":{"iopub.status.busy":"2023-09-14T13:35:28.894591Z","iopub.execute_input":"2023-09-14T13:35:28.895743Z","iopub.status.idle":"2023-09-14T13:35:28.919197Z","shell.execute_reply.started":"2023-09-14T13:35:28.89569Z","shell.execute_reply":"2023-09-14T13:35:28.917939Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Cross-Validation\nSince our dataset is small, the cross-validation could be a better way to measure both Linear and Polynomial model quality, which can reduce the randomness in determining model quality.\nFollowing a 5-folds cross-validation is applied on both models with help of `cross_val_score` in Scikit-Learn.","metadata":{}},{"cell_type":"code","source":"# compute the 5-folds cross-validation score of Linear Regression model\nlinear_reg_scores = cross_val_score(linear_reg_model,X,y,\n                                   scoring = 'neg_mean_squared_error',cv = 5)\nlinear_reg_rmse = np.sqrt(-linear_reg_scores)\n\n\n# compute the 5-folds cross-validation score of Polynomial Regression model\nX_ploy = poly_features.fit_transform(X)\npoly_reg_scores = cross_val_score(poly_reg_model,X_ploy,y,\n                                   scoring = 'neg_mean_squared_error',cv = 5)\nploy_reg_rmse = np.sqrt(-poly_reg_scores)","metadata":{"execution":{"iopub.status.busy":"2023-09-14T13:35:28.920805Z","iopub.execute_input":"2023-09-14T13:35:28.922278Z","iopub.status.idle":"2023-09-14T13:35:29.012293Z","shell.execute_reply.started":"2023-09-14T13:35:28.922227Z","shell.execute_reply":"2023-09-14T13:35:29.010262Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# define a function to display the various scores of the measure metrics\ndef display_score(scores):\n    print(\"RMSE Scores:\",scores)\n    print('Mean:', scores.mean())\n    print('Standard deviation:',scores.std())","metadata":{"execution":{"iopub.status.busy":"2023-09-14T13:35:29.019276Z","iopub.execute_input":"2023-09-14T13:35:29.020444Z","iopub.status.idle":"2023-09-14T13:35:29.029654Z","shell.execute_reply.started":"2023-09-14T13:35:29.020366Z","shell.execute_reply":"2023-09-14T13:35:29.027989Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print('Cross-validation scores of Linear Regression model:')\ndisplay_score(linear_reg_rmse)\n\nprint('\\nCross-validation scores of Polynomial Regression model:')\ndisplay_score(ploy_reg_rmse)","metadata":{"execution":{"iopub.status.busy":"2023-09-14T13:35:29.031769Z","iopub.execute_input":"2023-09-14T13:35:29.033075Z","iopub.status.idle":"2023-09-14T13:35:29.048466Z","shell.execute_reply.started":"2023-09-14T13:35:29.033026Z","shell.execute_reply":"2023-09-14T13:35:29.046875Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## 6. Prediction Visulization","metadata":{}},{"cell_type":"code","source":"fig,ax = plt.subplots(1,2,figsize=(16, 6))\n\n# plot the results of Linear Regression\ny_linear_reg = linear_reg_model.predict(X)\nax[0].plot(X, y, \"b.\",label = \"Original date samples\") # plot 'income' vs.'year'\nax[0].plot(X,y_linear_reg,\"g-\",linewidth=2, label = \"Linear Regression rredictions\")\nax[0].axis([1970,2024,0,50000])\nax[0].set_xlabel(\"Year\")\nax[0].set_ylabel(\"Per Capita Income\")\nax[0].set_title(\"Linear Regression\")\nax[0].legend()\nax[0].grid(True)\n\n\n\n# plot the results of Linear Regression\nX_poly = poly_features.fit_transform(X)\ny_poly_reg = poly_reg_model.predict(X_poly)\nax[1].plot(X, y, \"b.\",label = \"Original date samples\") # plot 'income' vs.'year'\nax[1].plot(X,y_poly_reg,\"g-\",linewidth=2, label = \"Linear Regression rredictions\")\nax[1].axis([1970,2025,0,50000])\nax[1].set_xlabel(\"Year\")\nax[1].set_ylabel(\"Per Capita Income\")\nax[1].set_title(\"Polynomial Regression(Degree=2)\")\nax[1].legend()\nax[1].grid(True)","metadata":{"execution":{"iopub.status.busy":"2023-09-14T13:35:29.05285Z","iopub.execute_input":"2023-09-14T13:35:29.053397Z","iopub.status.idle":"2023-09-14T13:35:29.862985Z","shell.execute_reply.started":"2023-09-14T13:35:29.053355Z","shell.execute_reply":"2023-09-14T13:35:29.86194Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"From the above both comparisions we can see that the Polynomial Regression can better fit the original dataset and the RMSE and deviation of RMSE in Polynomial Regression are much smaller than that in Linear Regression.","metadata":{}}],"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}}